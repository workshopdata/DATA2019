# Notes from DATA'19

_Note:_ These are rough-cut notes captured in real-time during the workshop.
Hopefully they can serve as useful pointers from some of the conversations
held at DATA'19.

## Using data
 - not enough on experimental setup
 - Absence of reproducibility
 - contrast vision, ML
 - CRAWDAD incentivization via linking to paper
    - Many repos for data, but people are not using them
    - Incentive to release dataset in more generic manner
 - Paper pub has experiments for the paper
 - Dataset pub looks broader
 - Pre-present before collecting dataset; guide collection parameters?
 - How to reward “1 day” effort? Do one-off experiments using infra on behalf of others (> ACK…)
 - Balancing U vs corporate output: if I use your dataset, you get access to my results?

### Needs
 - Guidelines for a good dataset
 — exploratory scripts, etc
 — details of collection methodology, extra normal events
 - The DATA checklist?
 — Good idea, but don’t put something too structured out there for a workshop
 — Explicitly invite papers that refine the checklist at the top of the checklist
 - What’s the incentive to use someone else’s data rather than collecting your own?

### Challenges
 - Something like “Occupancy data” is under-specific, need data that align with my actual goals; how to find?
 - Often aims do not align — collect data to satisfy your idea/problem, not all possible ideas
Data collection census
 - for categories, e.g. wireless, is there a list of key parameters
The data discovery problem
 - how to store, index, etc metadata
 - how to translate across domains, so people can discover the data they need
 - “what does the Google of datasets look like”
 - rich samples, snippets, etc; previews, or distribution summaries


## Next DATA

 - self-categorize into the types of problems this will be useful for?
 - feedback of, it would be nice if your data also had this
 - explicit welcoming of dataset extensions (this old dataset was missing X, added it (via synthesis or new measurement))
 - how to explicitly welcome pre-publication feedback on planned datasets before the actual collection
 - transition to living datasets and promote on-going efforts with renewal
 - Challenge track:
 — show use of (new results?) or enhancement or etc of a prior dataset, major bonus points for prior DATA dataset
 — use a dataset in a different way than it was intended
 - Have DATA TPC reject duplicate datasets, reject with “why make new instead of using prior?”
 - Solicit one-graph pitches early
 — Maybe play on loop during breaks

### Pros of this DATA
 - Space for conversations very good
 — Sometimes about the paper, sometimes more broad, all good
 — The questions sometimes should’ve targeted more than just the current speaker in this case
 — Fluid session schedule is good, but important to preserve non-zero time at the end of each session for full group
 - Talk lengths were good
 — Consider the same lengths total (10/15) but maybe maybe the ratio more biased to questions
 - Mid-talk interaction highly valued
 — Give presenters a heads up with presenter instructions email to encourage in-talk questions
 — Have session chairs remind/promote in-talk questions

### Cons of this DATA
 - Split track was okay, but not loved
 — If want/need to keep, consider lightning talks or posters or something to see what’s missed from the other
 — If there’s enough specialization in the subjects then it can be okay
 — The conference organizers don’t love


## Attendance

 - Session 1, 24
 - Session 2a, 8
 - Session 2b, 16
 - Session 3, 28
 - Session 4, 27
